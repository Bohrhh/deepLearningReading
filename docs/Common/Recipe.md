# 一份训练神经网络的配方

> 翻译自 [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)

几周前我在推特上发了一条题为“最常犯的关于神经网络的错误”的状态，并举了一些例子。这条推特的参与度比我预想的要高（包括网络研讨会😀）。很明显，许多人都有类似的遭遇，都体会到了“卷积层的工作原理”和“我们的卷积神经网络达到了SOTA结果”之间的鸿沟。

所以我觉得将这条推特的内容扩展到我尘封已久的博客，可能会是一件有趣的事。在这里，我不准备枚举所有的常见错误或者扩充它们，我打算挖的更深一点，谈一谈如何避免这些常见的错误（或者迅速的解决它们）。这个技巧就是要求你遵循一定的流程，而这个流程通常不会在文献或书籍中详细的描述。让我们从两个重要的观察出发，引出训练神经网络的配方。

#### 1） 神经网络的训练过程是一种有漏洞的抽象
据说训练神经网络是一件很容易的事。许多库和框架能够使用30行左右的神奇代码片段来解决你的数据问题，从而给你一个深刻（错误）的印象，这些个事是即插即用的。这些代码片段通常是下面这样的：
```
>>> your_data = # plug your awesome dataset here
>>> model = SuperCrossValidator(SuperDuper.fit, your_data, ResNet50, SGDOptimizer)
# conquer world here
```
这些库和示例冥冥之中让我们相信，这些接口和我们熟知的标准软件一样，是一种被称为API或者抽象的东西。拿网络请求的库为例：
```
>>> r = requests.get('https://api.github.com/user', auth=('user', 'pass'))
>>> r.status_code
200
```
这可太酷了！短短的几行代码将你从巨大负担中解脱出来，这负担包括query strings，urls，GET/POST requests，HTTP connections等等。这是我们熟悉的并且希望如此的。不幸的是，神经网络并不是这样。它不是“现成”的技术，我曾试图在我的推送“是的，你需要理解反向传播”中强调这一点。我在反向传播中挑出了一点并称之为抽象的漏洞，不幸的是情况远比你想象的糟糕。backprop+SGD不会奇迹般地使你的神经网络良好工作。batch norm不会奇迹般地使你的损失收敛的更快。RNNs不会奇迹般地帮你“插入”文本。即使你能够将问题转化为强化学习的形式，也不意味着你应该这样做。如果你坚持使用这项技术而不理解它是怎样工作的，你很有可能会失败。一如曾经的我...

#### 2） 神经网络的训练会悄悄的死掉
当你运行失败或者错误地配置了代码，你通常会得到一个异常。比如此处需要一个字符串而你输入了一个整数，这个函数只需要3个参数，导入失败，不存在这个关键字，这两个列表元素的数量不一致等类似的异常提示。除此之外，你通常可以对某个功能进行单元测试。

对于训练神经网络而言，这只是刚刚开始。即使所有的代码在语法上都是正确的，作为一个整体却没有得到想要的结果，这也是一言难尽的地方。“导致问题的空间”很大，逻辑上（和语法上相对）很难对它做单元测试。举一些例子，在数据增强的时候，你翻转了图片但是忘记了翻转图片相应的标签。你的神经网络仍然（令人震惊的）能够较好的工作，因为它学习到了这张图片是否翻转，并由此决定是否翻转预测的标签。你的自回归模型由于off-by-one，意外的将它的输出当成了输入。你尝试做梯度裁减却裁减了损失值，导致在训练过程中忽略了一些外部样例（outlier examples）。你使用预训练模型初始化你的权重，但是没有使用原始的mean。你埋头奋斗于正则化，学习率，衰减率，模型尺寸等。综上所述，你错误配置的神经网络只有你足够幸运的时候才会给你抛出异常，绝大多数时候它会默默的训练并悄悄的降低模型的性能。

所以，**“快速和激进”的神经网络训练方法是行不通的**，它只会让你遭受更多的折磨（**欲速则不达**这一点再怎么强调也不过分）。现在，在你想要使你的神经网络良好工作的过程中，遭受痛苦是一件很自然的事情，但是它可以通过尽可能的将各个步骤可视化，从而减轻你在debug中的痛苦。


## 配方

鉴于以上两点事实，我发展了一个具体的流程，当我打算利用神经网络去解决一个新的问题时，我便会遵循这个流程。你会发现这个流程认真对待了上述的两个问题。特别的，它的构建是从简单到复杂，在每一步我们都有明确的预想在这里会发生什么，并且在这里做实验来验证是否和我们预想中的一样。我们努力想要避免的是一次性引入大量的“未经验证”的复杂性，这些个复杂性必然会造成bug，并且需要花费巨大的时间精力去找到它。如果拿训练神经网络来做比喻，你写代码的时候需要一个非常小的学习率，并且每一步迭代之后需要在你的测试集上做完整的评估。


#### 1. 与数据融为一体
训练神经网络的第一步，不要去碰关于神经网络的任何代码，你应该首先彻底地检查你的数据。这一步至关重要。我喜欢花大量的时间（以小时计）去浏览上千张图片，理解数据的分布，寻找数据的模式。幸运的是，你的大脑非常擅长干这件事。有一次，我发现了数据中包含有重复的图片。还有一次，我发现了损坏的图片/标签。我寻找数据的不平衡和数据的偏置。我通常也会注意自己对这些数据分类的过程，这些也许会暗示出我们将要探索的模型结构。举一些例子，局部的特征是否足够，我们是否需要全局的信息？数据的变化（variation）是否剧烈，在哪个维度变化？哪个变化是虚假的，可以通过预处理过滤掉？空间位置是否重要，我们是否可以通过平均池化过滤掉它？图片的细节是否重要，它能够经受住多少次下采样？标签的噪声强不强烈？

此外，模型实际上可以看成是数据的压缩或者编译版，你可以查看你模型的预测结果并尝试去理解它可能的来由。如果你模型预测的结果和你在数据集中感受到的并不一致，那么这里可能有些问题了。

一旦你对数据有了定性的认识，建议你写一些简单的代码去搜索/过滤/整理任何你能想到的东西（比如标签，尺寸，数量等），并且将它们的分布/异常值可视化出来。异常值几乎总是会导致数据质量或者预处理的bug。


#### 2. 建立端到端的训练/评估框架 + 获得基线baseline

现在，我们充分理解了数据，我们是否可以开始研究迷人的Multi-scale ASPP FPN Resnet，并且训练一些棒极了的模型？当然，还不可以。否则，这就是一条痛苦的道路。我们下一步要做的是建立一个完整的训练评估结构，并且通过一系列的实验来说明这个结构是合理正确的。在这个阶段，你最好选择一些简单的模型，一些你不能搞杂的模型比如一个线性分类器，或者小型卷积网络。我们会训练它，可视化它的损失以及其他指标（比如正确率），模型的预测结果，并根据明确的假设做一些消融实验。

这个阶段的技巧：
- **固定随机种子**：总是固定随机种子，从而确保当你两次运行相同代码时得到相同的结果。这招帮你减少了一个变化的因素，让你分析问题时能够保持清醒。
- **简化**：确保舍弃任何不必要的幻想。举个例子，在这个阶段一定要取消任何数据增强，数据增强是一种正则化手段，这在之后的内容我们会作介绍，但是现在它却有可能造成愚蠢的bug。
- **在验证集上做评估**：画出模型在整个验证数据上的损失值。不要仅仅画出一个一个批次的损失值然后在tensorboard上作平滑显示。我们追求信息的正确性并且非常愿意为此花费更多的时间。
- **在开始阶段验证损失**：验证你的损失值是从正确的损失值开始的。举个例子，如果你的模型最后一层被正确的初始化，那么经过softmax，你大概会得到$-log(1/n_classes)$。同样道理，你也可以推出大概的值，如果你的损失函数是L2 regression或者Huber losses等等。
- **正确的初始化**：正确的初始化模型的最后一层。举个例子，如果你需要回归的数据的平均值为50，那么初始化最后一层的偏支5就要设为50。如果你有一个不平衡的数据集，正负样本比例为1：10，设置最后一层输出的logits，使得初始化时模型预测的结果为0.1。正确的设置会使得收敛更加迅速，避免“曲棍球棒”似的损失曲线，也就是在最初的几次迭代中，你的网络基本上只是在学习这个偏置。
- **人类基线**：监测那些人们能够检查并且可解释的指标，如正确率，而不是损失值。尽可能评估自己（人类）的准确性并和模型结果比较。或者，你也可以对测试数据打两次标签，将一个标签视作预测值，另一个标签视作真值。
- **独立的输入基线**：训练一个和输入无关的基线模型，（比如最简单的方式就是令模型的输入都是0），这应该比输入真实的数据表现的更差。也就是说，你可以由此判断模型是否真的提取到了输入数据的信息。
- **过拟合一个批次**：过拟合几个数据样本（比如两个）。这样我们逐渐增大模型的容量（比如增加网络层数或过滤器的数量）并验证模型是否能够达到最低的损失值（比如0）。我同样喜欢将真实标签和预测标签画在一起，来确定当损失收敛到最小值时，此两者能够完美的匹配上，否则，哪个地方肯定存在bug，在解决这个bug之前，我们就不能继续到下一个阶段。
- **验证训练损失的下降**：在这个阶段，你使用的是一个玩具模型，所以在数据集上训练通常是欠拟合的。尝试增加模型的体量，验证最终的损失值是否下降。
- **就在模型前可视化**：在什么地方可视化你的数据？对于这个问题的答案，毫不含糊，就应该在模型喂入数据之前如`y_hat=model(x)`（或者tf中，`sess.run`）。这是唯一的“真相的源头”。我已经记不清这个方法拯救我的次数，它帮我揭示出在数据预处理和数据增强阶段的问题。
- **动态的可视化预测结果**：在训练的过程中，我喜欢每隔一定的批次就可视化一下模型的预测结果。观察模型预测结果的变化，会赋予你对这个训练过程的一种难以置信的直觉。很多时，你会发现模型的不稳定，以某种方式来回“摆动”，这就说明模型在挣扎着适应你的数据。过低或过高的学习率也可通过“摆动”的数量看出来。
- **使用反向传播来绘制依赖关系**：你的训练代码通常包含复杂的，向量化的和广播操作。一个相对常见的，我曾遇到过几次的bug是，疏忽大意错误的在batch这个维度混淆了信息（比如使用view代替了transpose/permute）。令人沮丧的是，你的模型仍然可以正常的训练，因为它会学着忽略混淆的数据段。一种debug的方法是设置一个平凡的损失，比如模型输出`y_hat[i]`的和。执行反向传播，查看输入的梯度`input_grad`，验证是否`input_grad[i]`不等于0。同样的策略能够用在自回归模型中，因为t时刻依赖于1..t-1时刻。更一般的，梯度信息提供了模型中各个部分的依赖关系，这个信息能够帮助你debug。
- **泛化到一个特殊场景**：这一点偏向于一般的编程技巧。我时常看到有些人一开始就想着写一个通用的函数，然而却漏洞百出。我通常会先写一个特定的函数来解决我当前的工作，然后尝试着将它泛化成一个更通用的函数，并保证我能得到和之前函数相同的结果。这个方法经常被我用在向量化代码上，我几乎总是先写完全的for循环然后一个for一个for的将它转化为向量化的版本。

#### 3. 过拟合
在这个阶段，我们已经对数据有了一个好的理解，我们有了一个完整的训练评估流程。对任何一个模型我们能够可靠地（可复现地）计算它在数据集上的指标。我们有了一个与输入无关的基线和一个寻常到愚蠢的基线（需要去超越的），我们有一个大概的感觉人类在这个任务上能达到的水平（模型所要追求的）。这个阶段我们需要迭代出一个好的模型。

我将寻找一个好模型的方法分为两步：第一步用一个体量足够大的模型对数据过拟合（对比训练和验证的损失），然后对它进行合理的正则化（训练的损失会变大，验证的损失会减小）。如果我们无论用什么模型都无法得到足够小的训练损失，那么这表明我们哪里出错了。

这个阶段的技巧：
- **选择模型**：为了获得一个足够小的训练损失，你需要为你的数据选择一个合适的模型架构。当你开始选择的时候，我的建议是**不要逞英雄**。我曾见过许多人热衷于将神经网络模块像乐高一样以各种奇形怪状的方式堆叠起来。在项目的早期阶段，请抵制这种诱惑。我总是建议人们简单的去找到和你项目最相关的论文并且复制它们最简单的，表现优秀的模型。比如，你正在做图片分类，不要逞英雄，直接复制ResNet-50作为你的首次尝试。之后你可以做一些自定义的网络层去超越它。
- **Adam是安全的**：在获得baseline的开始阶段，我喜欢用Adam优化器，并设置学习率为3e-4。在我的经验中，adam对超参数更加不敏感。对于卷积神经网络而言，用SGD优化器，并合理的调节超参数，它总是能够比Adam好那么一点点，但是最优学习率的区域太窄了，并且不同问题还不一样。（如果你使用RNNs或者相关的序列模型，Adam是更常见的优化器。再一次强调，在你项目的开始阶段不要逞英雄，请遵循和你项目最相关的论文的做法）
- **一次只调整一点**：如果你有很多改进你的分类器的想法，我建议你一个一个尝试，并且保证它如你预想的一样对增强了你的模型。不要将你的所有想法一股脑的施加到你的模型上。这里有很多增加模型复杂度的方法，比如一开始使用小图片训练，然后增大图片尺寸。
- **不要相信默认的学习率衰减**：如果你参考了其他领域的代码，你需要尤其小心学习率衰减。不仅仅是因为不同的问题需要不同的学习率调整策略，更糟糕的是，在典型的实现中，学习率调整策略会和训练的epoch数目相关，而epoch数目和你数据量的大小直接相关。比如，ImageNet每30个epoch就会将学习率除以10，如果你训练的不是ImageNet，你不会想要相同的设置。如果你不够仔细，你的代码会将你的学习率过早的减少到0，使你的模型不再继续收敛。我自己的工作中，我总是取消学习率衰减而使用一个常数的学习率，只在最后阶段对学习率的衰减策略做调整。

#### 4. 正则化
一切顺利的话，我们已经有了一个大的模型，它能够过拟合训练数据。现在是时候对它进行正则化，牺牲模型在训练数据上的准确性来提高在验证数据上的准确性。

这个阶段的技巧：
- **采集更多的数据**：在任何实践中，正则化模型最好的最有效的方法就是增加真实的训练数据。一种常见的错误是在小数据集上花费大量的时间精力去增强模型，而不去增加你的训练数据。据我所知，增加数据几乎是唯一能够保证单调提高一个合理配置了的模型的性能的方法。当然还有模型的聚合，如果你能够承担它巨大的计算量（但是在聚合5个模型后，也就差不多不会提高了）。
- **数据增强**：仅次于真实数据的是半真半假数据，尝试做更激进的数据增强。
- **创造性的数据增强方法**：如果半真半假数据没有起作用，假数据也许能起点作用。人们寻找一些创造性的方法来扩充数据集。比如，域随机、使用模拟仿真、混合甚至GAN等。
- **预训练**：尽量使用预训练模型，即使你有足够的数据。至少预训练模型几乎不会对你的训练造成伤害。
- **坚持监督学习**：不要对无监督预训练过于兴奋。据我所知，在计算机视觉领域中，没有哪个版本获得了比监督学习更强的结果（虽然在NLP领域，BERT表现良好）
- **更小的输入维度**：去除那些包含杂乱信号的特征。如果你的数据集不够大的话，任何杂乱的信号都会增加你过拟合的风险。同样的，如果低层次的细节不会对你问题影响不大，那么可以尝试小一点的输入尺寸。
- **更小的模型**：在很多情况下，你可以使用专业领域的知识来对模型做一些约束，从而减小模型尺寸。比如，曾经在ImageNet分类任务中，模型的最后一层会使用全连接结构，但是现在已经被简单的平均池化层所取代，从而减少了大量参数。
- **减小batchsize**：由于batchnorm的正则化作用，小批次的batch意味着更强的正则化。这是因为一个批次的平均值和标准差是对整个数据平均值和标准差的近似，越小的批次意味着越大的不确定性。
- **drop**：对卷基层使用dropout2d（spatial dropout）。谨慎地使用这个方法，因为dropout似乎不能和batchnorm很好的协同工作。
- **weight decay**：增加参数衰减的惩罚项
- **提早结束**：根据验证集的损失判断是否已经过拟合，并且提前停止训练。
- **尝试更大的模型**：我将这一点放在最后且就在“提早结束”的下一条。虽然大模型在训练到最后显然会更加容易过拟合，但是如果提早结束模型的训练，那么它的结果通常比小模型要好。

最后，你更加相信你得到了一个合理的分类器，我会可视化模型第一层的权重，确保它是一个良好的边缘检测器。如果你第一层的过滤器长的像噪声，那么可能哪个地方出问题了。同样的，模型内部激活层的输出如果显示出古怪的信号，那也暗示着某个地方出问题了。

#### 5. 调参
你现在通过不停的迭代，探索了各种各样的模型结构，并且在验证数据集上获得了足够小的损失值。

接下来这个阶段的技巧：
- **随机网格搜索**：这里有许多超参数需要同时调节，为了确保覆盖所有的配置，最好使用网格搜索，而且是随机的网格搜索。直觉的，这是因为神经网络通常对某些超参数比对另一下超参数更加敏感。在这种情况下，如果参数a比参数b对模型的影响更大，你需要的是对a参数进行更细致的采样，而不是在某几个固定点上。
- **超参数优化**：这里有许多诱人的基于贝叶斯优化超参数的工具库，也有一些朋友说他确实获得了更好的结果。但是就我个人经验来说，探索不同模型结构，探索不同超参数最好的方法是使用实习生😀，哈哈，只是开个玩笑。


#### 6. 挤果汁
一旦你摸清了针对问题的最好的模型结构和超参数设置。你仍然能够使用一些tricks将你模型的性能进一步压榨出来。
- **多个模型的聚合**：模型聚合常常能保证使你提高2%的准确率。如果你无法接受测试时的计算量，你可以尝试使用蒸馏的方法。
- **继续训练**：我经常看到当人们发现验证集上的损失开始躺平的时候，他们就停止了模型的训练。在我的经验中，可以让模型继续训练一段非常长的时间。有一次，我偶然的让一个模型训练了一个寒假，当我一月份回来的时候，它达到了SOTA的结果🤯。


## 总结
当你阅读到这里时，你已经有了成功训练所需的所有知识：你对这项技术，数据集和可能遇到的问题有了深入的理解，你已经能够建立整个训练/评估的框架并且获得了很高的准确度，你已经开始探索越来越复杂的模型，在每一个步骤上都和你预想的一样，模型性能获得稳步的提升。你现在准备好阅读大量的文献，尝试多种多样的实验，并且达到SOTA的结果。祝你好运！