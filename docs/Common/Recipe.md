# 一份训练神经网络的配方

> 翻译自 [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)

几周前我在推特上发了一条题为“最常犯的关于神经网络的错误”的状态，并举了一些例子。这条推特的参与度比我预想的要高（包括网络研讨会😀）。很明显，许多人都有类似的遭遇，都体会到了“卷积层的工作原理”和“我们的卷积神经网络达到了SOTA结果”之间的鸿沟。

所以我觉得将这条推特的内容扩展到我尘封已久的博客，可能会是一件有趣的事。在这里，我不准备枚举所有的常见错误或者扩充它们，我打算挖的更深一点，谈一谈如何避免这些常见的错误（或者迅速的解决它们）。这个技巧就是要求你遵循一定的流程，而这个流程通常不会在文献或书籍中详细的描述。让我们从两个重要的观察出发，引出训练神经网络的配方。

#### 1） 神经网络的训练过程是一种有漏洞的抽象
据说训练神经网络是一件很容易的事。许多库和框架能够使用30行左右的神奇代码片段来解决你的数据问题，从而给你一个深刻（错误）的印象，这些个事是即插即用的。这些代码片段通常是下面这样的：
```
>>> your_data = # plug your awesome dataset here
>>> model = SuperCrossValidator(SuperDuper.fit, your_data, ResNet50, SGDOptimizer)
# conquer world here
```
这些库和示例冥冥之中让我们相信，这些接口和我们熟知的标准软件一样，是一种被称为API或者抽象的东西。拿网络请求的库为例：
```
>>> r = requests.get('https://api.github.com/user', auth=('user', 'pass'))
>>> r.status_code
200
```
这可太酷了！短短的几行代码将你从巨大负担中解脱出来，这负担包括query strings，urls，GET/POST requests，HTTP connections等等。这是我们熟悉的并且希望如此的。不幸的是，神经网络并不是这样。它不是“现成”的技术，我曾试图在我的推送“是的，你需要理解反向传播”中强调这一点。我在反向传播中挑出了一点并称之为抽象的漏洞，不幸的是情况远比你想象的糟糕。backprop+SGD不会奇迹般地使你的神经网络良好工作。batch norm不会奇迹般地使你的损失收敛的更快。RNNs不会奇迹般地帮你“插入”文本。即使你能够将问题转化为强化学习的形式，也不意味着你应该这样做。如果你坚持使用这项技术而不理解它是怎样工作的，你很有可能会失败。一如曾经的我...

#### 2） 神经网络的训练会悄悄的死掉
当你运行失败或者错误地配置了代码，你通常会得到一个异常。比如此处需要一个字符串而你输入了一个整数，这个函数只需要3个参数，导入失败，不存在这个关键字，这两个列表元素的数量不一致等类似的异常提示。除此之外，你通常可以对某个功能进行单元测试。

对于训练神经网络而言，这只是刚刚开始。即使所有的代码在语法上都是正确的，作为一个整体却没有得到想要的结果，这也是一言难尽的地方。“导致问题的空间”很大，逻辑上（和语法上相对）很难对它做单元测试。举一些例子，在数据增强的时候，你翻转了图片但是忘记了翻转图片相应的标签。你的神经网络仍然（令人震惊的）能够较好的工作，因为它学习到了这张图片是否翻转，并由此决定是否翻转预测的标签。你的自回归模型由于off-by-one，意外的将它的输出当成了输入。你尝试做梯度裁减却裁减了损失值，导致在训练过程中忽略了一些外部样例（outlier examples）。你使用预训练模型初始化你的权重，但是没有使用原始的mean。你埋头奋斗于正则化，学习率，衰减率，模型尺寸等。综上所述，你错误配置的神经网络只有你足够幸运的时候才会给你抛出异常，绝大多数时候它会默默的训练并悄悄的降低模型的性能。

所以，**“快速和激进”的神经网络训练方法是行不通的**，它只会让你遭受更多的折磨（**欲速则不达**这一点再怎么强调也不过分）。现在，在你想要使你的神经网络良好工作的过程中，遭受痛苦是一件很自然的事情，但是它可以通过尽可能的将各个步骤可视化，从而减轻你在debug中的痛苦。


## 配方

鉴于以上两点事实，我发展了一个具体的流程，当我打算利用神经网络去解决一个新的问题时，我便会遵循这个流程。你会发现这个流程认真对待了上述的两个问题。特别的，它的构建是从简单到复杂，在每一步我们都有明确的预想在这里会发生什么，并且在这里做实验来验证是否和我们预想中的一样。我们努力想要避免的是一次性引入大量的“未经验证”的复杂性，这些个复杂性必然会造成bug，并且需要花费巨大的时间精力去找到它。如果拿训练神经网络来做比喻，你写代码的时候需要一个非常小的学习率，并且每一步迭代之后需要在你的测试集上做完整的评估。


#### 1. 与数据融为一体
训练神经网络的第一步，不要去碰关于神经网络的任何代码，你应该首先彻底地检查你的数据。这一步至关重要。我喜欢花大量的时间（以小时计）去浏览上千张图片，理解数据的分布，寻找数据的模式。幸运的是，你的大脑非常擅长干这件事。有一次，我发现了数据中包含有重复的图片。还有一次，我发现了损坏的图片/标签。我寻找数据的不平衡和数据的偏置。我通常也会注意自己对这些数据分类的过程，这些也许会暗示出我们将要探索的模型结构。举一些例子，局部的特征是否足够，我们是否需要全局的信息？数据的变化（variation）是否剧烈，在哪个维度变化？哪个变化是虚假的，可以通过预处理过滤掉？空间位置是否重要，我们是否可以通过平均池化过滤掉它？图片的细节是否重要，它能够经受住多少次下采样？标签的噪声强不强烈？

此外，模型实际上可以看成是数据的压缩或者编译版，你可以查看你模型的预测结果并尝试去理解它可能的来由。如果你模型预测的结果和你在数据集中感受到的并不一致，那么这里可能有些问题了。

一旦你对数据有了定性的认识，建议你写一些简单的代码去搜索/过滤/整理任何你能想到的东西（比如标签，尺寸，数量等），并且将它们的分布/异常值可视化出来。异常值几乎总是会导致数据质量或者预处理的bug。


#### 2. 建立端到端的训练/评估框架 + 获得基线baseline

现在，我们充分理解了数据，我们是否可以开始研究迷人的Multi-scale ASPP FPN Resnet，并且训练一些棒极了的模型？当然，还不可以。否则，这就是一条痛苦的道路。我们下一步要做的是建立一个完整的训练评估结构，并且通过一系列的实验来说明这个结构是合理正确的。在这个阶段，你最好选择一些简单的模型，一些你不能搞杂的模型比如一个线性分类器，或者小型卷积网络。我们会训练它，可视化它的损失以及其他指标（比如正确率），模型的预测结果，并根据明确的假设做一些消融实验。

这个阶段的技巧：
- **固定随机种子**：总是固定随机种子，从而确保当你两次运行相同代码时得到相同的结果。这招帮你减少了一个变化的因素，让你分析问题时能够保持清醒。
- **简化**：确保舍弃任何不必要的幻想。举个例子，在这个阶段一定要取消任何数据增强，数据增强是一种正则化手段，这在之后的内容我们会作介绍，但是现在它却有可能造成愚蠢的bug。
- **在验证集上做评估**：画出模型在整个验证数据上的损失值。不要仅仅画出一个一个批次的损失值然后在tensorboard上作平滑显示。我们追求信息的正确性并且非常愿意为此花费更多的时间。
- **在开始阶段验证损失**：验证你的损失值是从正确的损失值开始的。举个例子，如果你的模型最后一层被正确的初始化，那么经过softmax，你大概会得到$-log(1/n_classes)$。同样道理，你也可以推出大概的值，如果你的损失函数是L2 regression或者Huber losses等等。
- **正确的初始化**：正确的初始化模型的最后一层。举个例子，如果你需要回归的数据的平均值为50，那么初始化最后一层的偏支5就要设为50。如果你有一个不平衡的数据集，正负样本比例为1：10，设置最后一层输出的logits，使得初始化时模型预测的结果为0.1。正确的设置会使得收敛更加迅速，避免“曲棍球棒”似的损失曲线，也就是在最初的几次迭代中，你的网络基本上只是在学习这个偏置。
- **人类基线**
- **独立的输入基线**
- **过拟合一个批次**
- **验证训练损失的下降**
- **就在模型前可视化**
- **动态的可视化预测结果**
- **使用反向传播来绘制依赖关系**
- **泛化到一个特殊场景**

#### 3. 过拟合
在这个阶段，我们已经对数据有了一个好的理解，我们有了一个完整的训练评估流程。对任何一个模型我们能够可靠地（可复现地）计算它在数据集上的指标。我们有了一个与输入无关的基线和一个寻常到愚蠢的基线（需要去超越的），我们有一个大概的感觉人类在这个任务上能达到的水平（模型所要追求的）。这个阶段我们需要迭代出一个好的模型。

我会将寻找一个好模型的方法分为

#### 4. 正则化

#### 5. 调参

#### 6. 挤果汁


## 总结
当你阅读到这里时，你已经有了成功训练所需的所有知识：你对这项技术，数据集和可能遇到的问题有了深入的理解，你已经能够建立整个训练/评估的框架并且获得了很高的准确度，你已经开始探索越来越复杂的模型，在每一个步骤上都和你预想的一样，模型性能获得稳步的提升。你现在准备好阅读大量的文献，尝试多种多样的实验，并且达到SOTA的结果。祝你好运！